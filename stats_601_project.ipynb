{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data frames\n",
    "\n",
    "log_pr = pd.read_pickle(\"./log_price.df\")\n",
    "volu = pd.read_pickle(\"./volume_usd.df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the negative 30-minutes backward log-returns to predict the 30-minutes forward log-returns\n",
    "\n",
    "def get_r_hat_baseline(A, B):\n",
    "    return -(A.iloc[-1] - A.iloc[-30]).values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of get_r_hat\n",
    "\n",
    "ACTIVE_R_HAT = \"baseline\"\n",
    "\n",
    "r_hat_implementations = {\n",
    "    \"baseline\": get_r_hat_baseline\n",
    "}\n",
    "\n",
    "def get_r_hat(A, B): \n",
    "    \"\"\"\n",
    "        A: 1440-by-10 dataframe of log prices with columns log_pr_0, ... , log_pr_9\n",
    "        B: 1440-by-10 dataframe of trading volumes with columns volu_0, ... , volu_9    \n",
    "        return: a numpy array of length 10, corresponding to the predictions for the forward 30-minutes returns of assets 0, 1, 2, ..., 9\n",
    "    \"\"\"\n",
    "    \n",
    "    return r_hat_implementations[ACTIVE_R_HAT](A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall correlation (The ranking is based on this metric on the testing dataset)\n",
    "# BASELINE: 0.040118694541047606\n",
    "\n",
    "def get_model_accuracy():\n",
    "    t0 = time.time()\n",
    "    dt = datetime.timedelta(days=1)\n",
    "    r_hat = pd.DataFrame(index=log_pr.index[30::10], columns=np.arange(10), dtype=np.float64)\n",
    "    for t in log_pr.index[30::10]: # compute the predictions every 10 minutes\n",
    "        r_hat.loc[t, :] = get_r_hat(log_pr.loc[(t - dt):t], volu.loc[(t - dt):t])\n",
    "    t_used = time.time() - t0\n",
    "    \n",
    "    r_fwd = (log_pr.shift(-30) - log_pr).iloc[30::10].rename(columns={f\"log_pr_{i}\": i for i in range(10)})\n",
    "    r_fwd.corrwith(r_hat)\n",
    "    \n",
    "    r_fwd_all = r_fwd.iloc[:-3].values.ravel() # the final 3 rows are NaNs. \n",
    "    r_hat_all = r_hat.iloc[:-3].values.ravel()\n",
    "    \n",
    "    return np.corrcoef(r_fwd_all, r_hat_all)[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dataset(window_size, dataset):\n",
    "    \"\"\"\n",
    "    window: look-back window size for constructing X (in minutes)\n",
    "    \"\"\"\n",
    "    window_dt = datetime.timedelta(minutes=window_size)\n",
    "    predict_dt = datetime.timedelta(minutes=30)\n",
    "\n",
    "    window_X = []\n",
    "    window_y = []\n",
    "\n",
    "    for t in dataset.index[window_size:-window_size:10]: # compute the predictions every 10 minutes\n",
    "        window_X.append(dataset.loc[(t - window_dt):t])\n",
    "        window_y.append(dataset.loc[t + predict_dt])\n",
    "        \n",
    "    return np.array(window_X), np.array(window_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_pr_vol_datasets(window_size):\n",
    "    \"\"\"\n",
    "    window: look-back window size for constructing X (in minutes)\n",
    "    \"\"\"\n",
    "    return construct_dataset(window_size, log_pr), construct_dataset(window_size, volu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 30 # in minutes\n",
    "log_pr_ds, volu_ds = construct_pr_vol_datasets(window_size)\n",
    "log_pr_X, log_pr_y = log_pr_ds\n",
    "volu_X, volu_y = volu_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040118694541047606"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_accuracy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
