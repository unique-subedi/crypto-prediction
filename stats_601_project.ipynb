{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashpatel5400/crypto-prediction/blob/main/stats_601_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "ccADqYamxwt0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b8f4686-353b-4b20-90da-d09e14503632"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('volu.csv', <http.client.HTTPMessage at 0x7fb2fb518610>)"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ],
      "source": [
        "import os\n",
        "import datetime\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.linear_model import Lasso \n",
        "import urllib.request\n",
        "\n",
        "url = \"https://media.githubusercontent.com/media/yashpatel5400/crypto-prediction/main/log_pr.csv\"\n",
        "urllib.request.urlretrieve(url, \"log_pr.csv\")\n",
        "\n",
        "url = \"https://media.githubusercontent.com/media/yashpatel5400/crypto-prediction/main/volu.csv\"\n",
        "urllib.request.urlretrieve(url, \"volu.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_pr = pd.read_csv(\"log_pr.csv\", index_col= 0)\n",
        "volu = pd.read_csv(\"volu.csv\", index_col= 0)\n",
        "\n",
        "log_pr.index = pd.to_datetime(log_pr.index)\n",
        "volu.index = pd.to_datetime(volu.index)\n",
        "\n",
        "print(log_pr.shape)\n",
        "\n",
        "num_test = 5000\n",
        "log_pr_test = log_pr.iloc[-num_test:]\n",
        "log_pr = log_pr.iloc[:-num_test]\n",
        "\n",
        "volu_test = volu.iloc[-num_test:]\n",
        "volu = volu.iloc[:-num_test]\n",
        "\n",
        "print(log_pr_test.shape)\n"
      ],
      "metadata": {
        "id": "9KV8jE9ryGMl",
        "outputId": "f4d63061-4bae-4988-b8b6-2445db00930c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(264960, 10)\n",
            "(5000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def construct_features(log_pr_df, vol_df):\n",
        "    df = log_pr_df.copy()\n",
        "    ema21 = log_pr_df.ewm(span=21, min_periods=5, adjust=False).mean().fillna(1)\n",
        "    ema35 = log_pr_df.ewm(span=35, min_periods=10, adjust=False).mean().fillna(1)\n",
        "    # ema80 = log_pr_df.ewm(span=80, min_periods=20, adjust=False).mean().fillna(1)\n",
        "    # ema250 = log_pr_df.ewm(span=250, min_periods=30, adjust=False).mean().fillna(1)\n",
        "\n",
        "    df = pd.concat([df], axis=1)\n",
        "    return df"
      ],
      "metadata": {
        "id": "eRn3ihxa2ENe"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "yrHfzn9Zxwt2"
      },
      "outputs": [],
      "source": [
        "def construct_dataset(window_size, features, log_prices):\n",
        "    \"\"\"\n",
        "    window: look-back window size for constructing X (in minutes)\n",
        "    \"\"\"\n",
        "    window_dt = datetime.timedelta(minutes=window_size)\n",
        "    predict_dt = datetime.timedelta(minutes=30)\n",
        "\n",
        "    window_X = []\n",
        "    window_y = []\n",
        "\n",
        "    for t in features.index[window_size:-window_size:10]: # compute the predictions every 10 minutes\n",
        "      window_X.append(features.loc[(t - window_dt):t])\n",
        "      window_y.append(log_prices.loc[t + predict_dt] - log_prices.loc[t])\n",
        "        \n",
        "    return np.array(window_X), np.array(window_y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = construct_features(log_pr, volu)\n",
        "window_size = 60 # in minutes\n",
        "X, y = construct_dataset(window_size, features, log_pr)\n",
        "\n",
        "X_train = X\n",
        "y_train = y\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "YNSlCpcVeBhc",
        "outputId": "07bc1ddd-2552-4c46-b7b9-9412c431cffa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25984, 61, 10)\n",
            "(25984, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTMs"
      ],
      "metadata": {
        "id": "ZS5aTovmSQTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable \n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "izfnP2X2ZrLz",
        "outputId": "dad79a1d-13d0-4602-d0eb-9d6e3edf1fa7"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: 'zmq.backend.cython.message.Frame.__dealloc__'\n",
            "Traceback (most recent call last):\n",
            "  File \"zmq/backend/cython/checkrc.pxd\", line 13, in zmq.backend.cython.checkrc._check_rc\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensors = Variable(torch.Tensor(X_train).to(device))\n",
        "y_train_tensors = Variable(torch.Tensor(y_train).to(device))\n",
        "\n",
        "print(\"Training Shape\", X_train_tensors.shape, y_train_tensors.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt55VF6CYXx1",
        "outputId": "7628cd9b-89be-4000-d2ae-9449c9e3789e"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Shape torch.Size([25984, 61, 10]) torch.Size([25984, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM1(nn.Module):\n",
        "    def __init__(self, output_size, input_size, hidden_size, num_layers):\n",
        "        super(LSTM1, self).__init__()\n",
        "        self.output_size = output_size #number of classes\n",
        "        self.num_layers = num_layers #number of layers\n",
        "        self.input_size = input_size #input size\n",
        "        self.hidden_size = hidden_size #hidden state\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
        "                          num_layers=num_layers, batch_first=True) #lstm\n",
        "        self.fc1 = nn.Linear(hidden_size, 64)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc = nn.Linear(32, output_size) #fully connected last layer\n",
        "    \n",
        "    def forward(self,x):\n",
        "        output, (hn, cn) = self.lstm(x) #lstm with input, hidden, and internal state\n",
        "        hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
        "        out = self.fc1(hn)\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.fc(out) #Final Output\n",
        "        return out"
      ],
      "metadata": {
        "id": "CQHjSqpJSPxG"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100 #1000 epochs\n",
        "learning_rate = 0.001 #0.001 lr\n",
        "\n",
        "input_size = X_train.shape[-1] #number of features\n",
        "print(input_size)\n",
        "hidden_size = 128 #number of features in hidden state\n",
        "num_layers = 1 #number of stacked lstm layers\n",
        "\n",
        "output_size = 10 #number of output classes\n",
        "\n",
        "lstm1 = LSTM1(output_size, input_size, hidden_size, num_layers) \n",
        "lstm1 = lstm1.to(device)\n",
        "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
        "optimizer = torch.optim.Adam(lstm1.parameters(), lr=learning_rate)\n",
        "\n",
        "print(X_train_tensors.shape)"
      ],
      "metadata": {
        "id": "9ndy3ZdgV94S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37e612b3-869b-4465-fc22-4125e7e5ddf1"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "torch.Size([25984, 61, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  outputs = lstm1.forward(X_train_tensors) \n",
        "  optimizer.zero_grad() \n",
        " \n",
        "  # obtain the loss function\n",
        "  loss = criterion(outputs, y_train_tensors)\n",
        " \n",
        "  loss.backward() \n",
        " \n",
        "  optimizer.step() #improve from loss, i.e backprop\n",
        "  if epoch % 2 == 0:\n",
        "    print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item())) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "08j9WqBBWsSm",
        "outputId": "c0c61957-dfb4-413e-c667-ccdbdcdd735f"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, loss: 0.00979\n",
            "Epoch: 2, loss: 0.00843\n",
            "Epoch: 4, loss: 0.00724\n",
            "Epoch: 6, loss: 0.00600\n",
            "Epoch: 8, loss: 0.00471\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-9628496afa77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#improve from loss, i.e backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch: %d, loss: %1.5f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm1 = lstm1.to(torch.device(\"cpu\"))\n",
        "torch.save(lstm1.state_dict(), \"/content/lstm_model.pth\")"
      ],
      "metadata": {
        "id": "yzZ-1cPQc436"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print( np.expand_dims(log_pr.iloc[-31:, :].to_numpy(), 0).shape)"
      ],
      "metadata": {
        "id": "uZvySfrKfYEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm1.load_state_dict(torch.load(\"/content/lstm_model.pth\"))\n",
        "lstm1.eval()\n",
        "lstm1 = lstm1.to(torch.device(\"cpu\"))"
      ],
      "metadata": {
        "id": "blDR3M_w4Kiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GBoost"
      ],
      "metadata": {
        "id": "1gf6H1IXWs9j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDMGIEIaxwt5"
      },
      "outputs": [],
      "source": [
        "class GBoost:\n",
        "    def __init__(self, num_assets=10):\n",
        "        self.models = []\n",
        "        self.num_assets = num_assets\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        for asset_index in range(10):\n",
        "            asset_X = np.array(X[:, :, asset_index])\n",
        "            asset_y = np.array(y[:, asset_index])\n",
        "\n",
        "            # X_train = np.array(one_asset_X[:-5000, :])\n",
        "            # y_train = np.array(one_asset_y[:-5000])\n",
        "\n",
        "            model = lgb.LGBMRegressor()\n",
        "            model.fit(asset_X, asset_y)\n",
        "\n",
        "            self.models.append(model)\n",
        "\n",
        "    def predict_one(self, X): #given data for just one sequence.\n",
        "        final_predictions = []\n",
        "        for asset_index in range(10):\n",
        "            features = np.expand_dims(X[-31:, asset_index], 0)\n",
        "            pred = self.models[asset_index].predict(features)\n",
        "            final_predictions.append(pred)\n",
        "        final_predictions = np.array(final_predictions).squeeze()\n",
        "        return final_predictions\n",
        "\n",
        "    def predict(self, X): #multiple sequences:\n",
        "        final_predictions = []\n",
        "        for i in range(len(X)):\n",
        "            tmp_predictions = []\n",
        "            for asset_index in range(10):\n",
        "                features = np.array(np.expand_dims(X[i, -31:, asset_index], 0))\n",
        "                pred = self.models[asset_index].predict(features)[0]\n",
        "                tmp_predictions.append(pred)\n",
        "            final_predictions.append(tmp_predictions)\n",
        "            \n",
        "        return np.array(final_predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train \n",
        "boost_model = GBoost()\n",
        "boost_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "h7ZBn1JEhUzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GBoost part 2"
      ],
      "metadata": {
        "id": "vcDi4DmPggul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_0 = lgb.LGBMRegressor()\n",
        "X_train_asset0 = np.array(X_train[:, :, 0])\n",
        "X_train_asset2 = np.array(X_train[:, :, 2])\n",
        "X_train_asset3 = np.array(X_train[:, :, 3])\n",
        "X_train_asset1 = np.array(X_train[:, :, 1])\n",
        "\n",
        "y_train_asset0 = np.array(y_train[:, 0])\n",
        "y_train_asset2 = np.array(y_train[:, 2])\n",
        "y_train_asset3 = np.array(y_train[:, 3])\n",
        "y_train_asset1 = np.array(y_train[:, 1])\n",
        "\n",
        "model_2 = lgb.LGBMRegressor()\n",
        "model_3 = lgb.LGBMRegressor()\n",
        "model_1 = lgb.LGBMRegressor()\n",
        "\n",
        "\n",
        "model_0.fit(X_train_asset0, y_train_asset0)\n",
        "model_2.fit(X_train_asset2, y_train_asset2)\n",
        "model_3.fit(X_train_asset3, y_train_asset3)\n",
        "model_1.fit(X_train_asset1, y_train_asset1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9hoezbohP2r",
        "outputId": "48611caf-8d96-4a3b-963e-1b08d394ea10"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor()"
            ]
          },
          "metadata": {},
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation"
      ],
      "metadata": {
        "id": "PqnE4kzzhSsY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "9mprkHj3xwt6"
      },
      "outputs": [],
      "source": [
        "# Use the negative 30-minutes backward log-returns to predict the 30-minutes forward log-returns\n",
        "#predict the log price, and then do correlation\n",
        "\n",
        "def get_r_hat_baseline(A, B):\n",
        "    return -(A.iloc[-1] - A.iloc[-30]).values "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "id": "Ii-0UMoWxwt6"
      },
      "outputs": [],
      "source": [
        "def get_r_hat_gboost(A, B):\n",
        "    preds = boost_model.predict_one(A.to_numpy())\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_r_hat_lstm(A, B):\n",
        "  input = np.expand_dims(construct_features(A, B).values, axis=0)\n",
        "  input = Variable(torch.Tensor(input))\n",
        "  pred = lstm1(input).detach().cpu().numpy()\n",
        "  return pred.squeeze()"
      ],
      "metadata": {
        "id": "u41btF83fFM8"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_r_hat_complex(A, B):\n",
        "  input = construct_features(A, B)\n",
        "  tmp = -(input.iloc[-1] - input.iloc[-30]).values\n",
        "  asset_0_pred = model_0.predict(np.expand_dims(input.iloc[-61:, 0].values, axis=0)) \n",
        "  asset_2_pred = model_2.predict(np.expand_dims(input.iloc[-61:, 2].values, axis=0))\n",
        "  asset_3_pred = model_3.predict(np.expand_dims(input.iloc[-61:, 3].values, axis=0))\n",
        "  asset_1_pred = model_1.predict(np.expand_dims(input.iloc[-61:, 1].values, axis=0))\n",
        "  tmp[0] = asset_0_pred[0]\n",
        "  tmp[2] = asset_2_pred[0]\n",
        "  tmp[3] = asset_3_pred[0]\n",
        "  tmp[1] = asset_1_pred[0]\n",
        "\n",
        "  return tmp"
      ],
      "metadata": {
        "id": "1tEScM3UotCy"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_r_hat_simple(A, B):\n",
        "  input = construct_features(A, B)\n",
        "  return -(input.iloc[-1] - input.iloc[-30]).values "
      ],
      "metadata": {
        "id": "_vGoGX5jot55"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "id": "qMc8AuzExwt6"
      },
      "outputs": [],
      "source": [
        "# An example of get_r_hat\n",
        "\n",
        "ACTIVE_R_HAT = \"complex\"\n",
        "\n",
        "r_hat_implementations = {\n",
        "    \"baseline\": get_r_hat_baseline, \n",
        "    \"gboost\": get_r_hat_gboost,\n",
        "    \"lstm\": get_r_hat_lstm,\n",
        "    \"simple\":get_r_hat_simple,\n",
        "    \"complex\": get_r_hat_complex\n",
        "}\n",
        "\n",
        "def get_r_hat(A, B): \n",
        "    \"\"\"\n",
        "        A: 1440-by-10 dataframe of log prices with columns log_pr_0, ... , log_pr_9\n",
        "        B: 1440-by-10 dataframe of trading volumes with columns volu_0, ... , volu_9    \n",
        "        return: a numpy array of length 10, corresponding to the predictions for the forward 30-minutes returns of assets 0, 1, 2, ..., 9\n",
        "    \"\"\"\n",
        "    return r_hat_implementations[ACTIVE_R_HAT](A, B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "id": "RN6LhZA_xwt7"
      },
      "outputs": [],
      "source": [
        "def get_model_corr(test_log_pr, test_volu):\n",
        "    t0 = time.time()\n",
        "    dt = datetime.timedelta(days=1)\n",
        "    r_hat = pd.DataFrame(index=test_log_pr.index[1440::10], columns=np.arange(10), dtype=np.float64)\n",
        "    for t in test_log_pr.index[1440::10]: # compute the predictions every 10 minutes\n",
        "        r_hat.loc[t, :] = get_r_hat(test_log_pr.loc[(t - dt):t], test_volu.loc[(t - dt):t])\n",
        "    t_used = time.time() - t0\n",
        "    \n",
        "    r_fwd = (test_log_pr.shift(-30) - test_log_pr).iloc[1440::10].rename(columns={f\"input_df_{i}\": i for i in range(10)})\n",
        "    r_fwd.corrwith(r_hat)\n",
        "    \n",
        "    r_fwd_all = r_fwd.iloc[:-3].values.ravel() # the final \"ignore_rows\" rows are NaNs. \n",
        "    r_hat_all = r_hat.iloc[:-3].values.ravel()\n",
        "    return np.corrcoef(r_fwd_all, r_hat_all)[0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIOf2aSxxwt8",
        "outputId": "56058f3f-581a-4298-a7d5-4444091fc369"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0913408759706439"
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ],
      "source": [
        "# log_pr_test = log_pr.iloc[-num_test:]\n",
        "# volu_test = volu.iloc[-num_test:]\n",
        "get_model_corr(log_pr_test, volu_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ZS5aTovmSQTc",
        "1gf6H1IXWs9j"
      ],
      "name": "stats_601_project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}